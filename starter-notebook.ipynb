{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Clasification Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**2110ACDS_T7**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### EDSA-Climate Change Belief Analysis 2022\n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Our clients would like to know people's perception on climate change, whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received, which will increasing their insights and informing future marketing strategies.\n",
    "\n",
    "SWAT_Team_7 has been consulted to create a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "### Process\n",
    "\n",
    "- 1. analyse the supplied data;\n",
    "- 2. identify potential errors in the data and clean the existing data set;\n",
    "- 3. determine if additional features can be added to enrich the data set;\n",
    "- 4. build a model that is capable of forecasting the three hourly demand shortfalls;\n",
    "- 5. evaluate the accuracy of the best machine learning model;\n",
    "- 6. determine if a person believes in climate change or not, and\n",
    "- 7. explain the inner working of the model to a non-technical audience.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c044ea",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "For this section, we carry out two different types of data analysis:\n",
    "- Univariate \\\n",
    "    i. non-graphical \\\n",
    "    ii. graphical \n",
    "- Multivariate \\\n",
    "    i. non-graphical \\\n",
    "    ii. graphical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e773ee3",
   "metadata": {},
   "source": [
    "#### Univariate Non-Graphical Analysis\n",
    "For this analysis, we are going to view dataset on the below checks:  \\\n",
    "    i.  Check for the presence of *null* values  \\\n",
    "    ii. Descriptive statistical values *mean, std, minimum, quatiles, maximum, and kurtosis*  \n",
    "    iii. Dataset data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at data statistics\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254e20c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  15819 non-null  int64 \n",
      " 1   message    15819 non-null  object\n",
      " 2   tweetid    15819 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 370.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data types for all columns\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f855bfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>15819.0</td>\n",
       "      <td>0.917504</td>\n",
       "      <td>0.836537</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <td>15819.0</td>\n",
       "      <td>501719.433656</td>\n",
       "      <td>289045.983132</td>\n",
       "      <td>6.0</td>\n",
       "      <td>253207.5</td>\n",
       "      <td>502291.0</td>\n",
       "      <td>753769.0</td>\n",
       "      <td>999888.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count           mean            std  min       25%       50%  \\\n",
       "sentiment  15819.0       0.917504       0.836537 -1.0       1.0       1.0   \n",
       "tweetid    15819.0  501719.433656  289045.983132  6.0  253207.5  502291.0   \n",
       "\n",
       "                75%       max  \n",
       "sentiment       1.0       2.0  \n",
       "tweetid    753769.0  999888.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at data statistics\n",
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b05422a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0.122976\n",
       "tweetid     -1.193356\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf02c5b",
   "metadata": {},
   "source": [
    "From the above analysis thus far, it is evidence that we only have two numeric colunms. \n",
    "However we suspect that one of these columns(tweetid) contains unique values in each row, while the other column(sentiment) from the name, we infere that it is our label, hence contains a minimum of two different values.\n",
    "\n",
    "To confirm the above, we write a function that takes in a dataframe and a column-id, to give an output which is the number of unique values in the column as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95c1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_val(df, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column name, \n",
    "        and ouputs an interger, which is the number of unique \n",
    "        values in the column.\n",
    "    \"\"\"\n",
    "    return df[col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a22e6980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers of unique values in the sentiment column is : 4\n"
     ]
    }
   ],
   "source": [
    "# Check the numbers of unique values for the sentiment column\n",
    "print(f'The numbers of unique values in the sentiment column is : {unique_val(df_train, \"sentiment\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e48c18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers of unique values in the tweetid column is : 15819\n"
     ]
    }
   ],
   "source": [
    "# Check the numbers of unique values for the tweetid column\n",
    "print(f'The numbers of unique values in the tweetid column is : {unique_val(df_train, \"tweetid\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e2880",
   "metadata": {},
   "source": [
    "From the above results, the sentiment column contains four different unique values, and we want to see how this values\n",
    "are distributed in the column.\n",
    "To achieve this, we write a function called *unique_val_count*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80cd6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_val_count(df, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column name, \n",
    "        and ouputs a dictionary, which contains the unique values as a key, and the numbers as values.\n",
    "    \"\"\"\n",
    "    distribution = {}\n",
    "    unique_vals = df[col].unique()\n",
    "    for val in unique_vals:\n",
    "        distribution[val] = df[df[col] == val][col].count()\n",
    "    \n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29ddf06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 8530, 2: 3640, 0: 2353, -1: 1296}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_val_count(df_train, 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd562db5",
   "metadata": {},
   "source": [
    "### Univariate graphical inspection of data\n",
    "For this analysis, we view the individual colunms using histogram plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f47bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot of label classes\n",
    "fig,ax = plt.subplots()\n",
    "df_train['sentiment'].value_counts().plot(kind = 'bar', facecolor='g', alpha=0.65)\n",
    "ax.set_xlabel('Sentiments')\n",
    "ax.set_ylabel('Sentiments count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74b341",
   "metadata": {},
   "source": [
    "# PUT IN WORD CLOUD BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1525812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77b34f68",
   "metadata": {},
   "source": [
    "## Also include findings from world cloud in EDA summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f2a7d",
   "metadata": {},
   "source": [
    "### EDA summary\n",
    "- The dataset contains three columns (sentiments, message and tweetid)\n",
    "- Sentiments and tweetid are of numeric data type, while message is non-numeric\n",
    "- tweetid is a clumn with uniques values acreoss the entire rows of the dataset\n",
    "- sentiments columns contains for different unique values (-1, 0, 1 &2) with different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de51df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at feature distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to: clean the dataset, and possibly create new features - as identified in the EDA phase. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ced808",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    "\n",
    "### Removing Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba0d8c",
   "metadata": {},
   "source": [
    "For the given dataset, we identified that the *message* column contains the novel tweet for each userid, which we are espected to classify. \n",
    "For us to proceed we have to carry out cleaning on this messages. This cleaning will be achieved through:\n",
    "* identify and remove web-urls from the main message \n",
    "* idendify and remove words started with '#'\n",
    "* idendify and remove words started with '@'\n",
    "* making everything lower case\n",
    "* removing punctuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab1ea8",
   "metadata": {},
   "source": [
    "#### Remove web-url from message\n",
    "\n",
    "We write a function called *delete_url*. This function uses regex to identify web-url in a column and remove same from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_url(data, col):\n",
    "    \"\"\"\n",
    "        Accepts a dataframe and col., removes web urls from the col.\n",
    "        returns a new dataframe \n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "    subs_url = ''\n",
    "    df[col] = df[col].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98fa8207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with message colun void of url links\n",
    "new_df_train = delete_url(df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84eea17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!?  via @mashable\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the above operation was successful \n",
    "new_df_train['message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59692724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['message'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b3c36",
   "metadata": {},
   "source": [
    "### Remove '#' and '@' words\n",
    "\n",
    "We write a function *delete_tags*, to identify and remove words started with '#' and '@'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92a0f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tags(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a col, removes all words started with '#' and '@' in the column,\n",
    "        and returns a new dataframe\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    pattern_tags = r'#\\w+[#?]'\n",
    "    pattern_2 = r'@\\w+'\n",
    "    subs_tag = ''\n",
    "    df[col] = df[col].replace(to_replace = pattern_tags, value = subs_tag, regex = True)\n",
    "    df[col] = df[col].replace(to_replace = pattern_2, value = subs_tag, regex = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8422fbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT : Researchers say we have three years to ac...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>WIRED : 2016 was a pivotal year in the war on...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT : It's 2016, and a racist, sexist, climate ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT : Researchers say we have three years to ac...   698562\n",
       "3          1   WIRED : 2016 was a pivotal year in the war on...   573736\n",
       "4          1  RT : It's 2016, and a racist, sexist, climate ...   466954"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with message colun void of url links\n",
    "new_df_train = delete_tags(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ec814",
   "metadata": {},
   "source": [
    "### Convert capitalized words to lowercase words\n",
    "\n",
    "We write a function *word_converter* to convert capitalized words to lowercase words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcb93891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_converter(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and col, converts all capitalized words in the column to lowercase,\n",
    "        and returns a new dataframe.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    df[col] = df[col].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ac78c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt : researchers say we have three years to ac...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired : 2016 was a pivotal year in the war on...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt : it's 2016, and a racist, sexist, climate ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief doesn't think carbon di...   625221\n",
       "1          1  it's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  rt : researchers say we have three years to ac...   698562\n",
       "3          1   wired : 2016 was a pivotal year in the war on...   573736\n",
       "4          1  rt : it's 2016, and a racist, sexist, climate ...   466954"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with all words in the message column converted to its lowercase form\n",
    "new_df_train = word_converter(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f51a4",
   "metadata": {},
   "source": [
    "### Remove punctuation\n",
    "\n",
    "We write a function *remove_punc* that uses the string package from python to remove punctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87a4a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column, uses python string package to identify and remove all\n",
    "        punctions in the column. It returns a new dataframe\n",
    "    \"\"\"\n",
    "    def operation(post):\n",
    "        return ''.join([l for l in post if l not in string.punctuation])\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    df[col] = df[col].apply(operation)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0deb07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221\n",
       "1          1  its not like we lack evidence of anthropogenic...   126103\n",
       "2          2  rt  researchers say we have three years to act...   698562\n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736\n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with the message colmn void of punctuations\n",
    "new_df_train = remove_punc(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb8adf",
   "metadata": {},
   "source": [
    "### Remove new lines (\\n) from the start of any words\n",
    "\n",
    "We noticed that some words start with '\\n' and this is a short form for new line in programming, words started with \\n looses its original meaning.\n",
    "\n",
    "Hence we write a function remove_new_line to execute this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ee9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_new_line(data, col):\n",
    "    \"\"\"\n",
    "        Takes in a dataframe and a column, returns a new dataframe with a new column void of new line command\n",
    "    \"\"\"\n",
    "\n",
    "    def operation(text):\n",
    "        result = re.sub(\"\\n\", \"\", text)\n",
    "        return result\n",
    "\n",
    "    df = data.copy()\n",
    "    \n",
    "    df[col] = df[col].apply(operation)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7548016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221\n",
       "1          1  its not like we lack evidence of anthropogenic...   126103\n",
       "2          2  rt  researchers say we have three years to act...   698562\n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736\n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with the message colmn void of punctuations\n",
    "new_df_train = remove_new_line(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa36e01",
   "metadata": {},
   "source": [
    "### Tokenisation\n",
    "\n",
    "We write a function *tokenizer* to tokenize the words in the message column and store same in a new column named *message_tok*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "897e0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a col, creates a new column to store the tokenized words\n",
    "        in the inputed column, and returns a new dataframe.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    tokeniser = TreebankWordTokenizer()\n",
    "    df['message_tok'] = df[col].apply(tokeniser.tokenize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea5182f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2  rt  researchers say we have three years to act...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954   \n",
       "\n",
       "                                         message_tok  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...  \n",
       "2  [rt, researchers, say, we, have, three, years,...  \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...  \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold the tokens from message column\n",
    "new_df_train = tokenizer(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c845c",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "We write a function *stem_words* to transform all words in the *message_tok* column to its root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4957f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(data, col):\n",
    "    \"\"\"\n",
    "        Takes in a dataframe and a column, converts the words in the column to it root form,\n",
    "        with the aid of SnowballStemmer class from the nltk package.\n",
    "        Returns a new dataframe with an additional column \"message_stem\"\n",
    "    \"\"\"\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    def operation(words, stemmer):\n",
    "        return [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    df = data.copy()\n",
    "    df[\"message_stem\"] = df[col].apply(operation, args=(stemmer, ))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09d2c7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[rt, research, say, we, have, three, year, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "      <td>[wire, 2016, was, a, pivot, year, in, the, war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climat,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2  rt  researchers say we have three years to act...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...   \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...   \n",
       "\n",
       "                                        message_stem  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [it, not, like, we, lack, evid, of, anthropoge...  \n",
       "2  [rt, research, say, we, have, three, year, to,...  \n",
       "3  [wire, 2016, was, a, pivot, year, in, the, war...  \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climat,...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold root words from stemmer\n",
    "new_df_train = stem_words(new_df_train, 'message_tok')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c55afc",
   "metadata": {},
   "source": [
    "### Larmming\n",
    "\n",
    "We write a function *lam_words* to transform all words in the *message_tok* column to its root form using Lemmatization, to enable us acrter for the shortfall in stemming above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "148e0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lam_words(data, col):\n",
    "    \"\"\"\n",
    "        Takes in a dataframe and a column, converts the words in the column to it root form,\n",
    "        with the aid of WordNetLemmatizer class from the nltk package.\n",
    "        Returns a new dataframe with an additional column \"message_lam\"\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def operation(words, lemmatizer):\n",
    "        return [lemmatizer.lemmatize(word) for word in words] \n",
    "    df = data.copy()\n",
    "    df[\"message_lam\"] = df[col].apply(operation, args=(lemmatizer, ))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea6ae293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "      <th>message_lam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[rt, research, say, we, have, three, year, to,...</td>\n",
       "      <td>[rt, researcher, say, we, have, three, year, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "      <td>[wire, 2016, was, a, pivot, year, in, the, war...</td>\n",
       "      <td>[wired, 2016, wa, a, pivotal, year, in, the, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climat,...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2  rt  researchers say we have three years to act...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...   \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...   \n",
       "\n",
       "                                        message_stem  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evid, of, anthropoge...   \n",
       "2  [rt, research, say, we, have, three, year, to,...   \n",
       "3  [wire, 2016, was, a, pivot, year, in, the, war...   \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climat,...   \n",
       "\n",
       "                                         message_lam  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...  \n",
       "2  [rt, researcher, say, we, have, three, year, t...  \n",
       "3  [wired, 2016, wa, a, pivotal, year, in, the, w...  \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climate...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold root words from stemmer\n",
    "new_df_train = lam_words(new_df_train, 'message_tok')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4510e4f",
   "metadata": {},
   "source": [
    "### Remove stop words\n",
    "Stop words are words which do not contain important significance to be used in Search Queries. \n",
    "We write a function *remove_stop_word*, that removes stop words in a speified column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3ebade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data, col):\n",
    "    \"\"\"\n",
    "        Takes a dataframe and a column, creates a new dataframe with a new column no_stop_word from the input\n",
    "        dataframe and column, returns the new column\n",
    "    \"\"\"\n",
    "    def operation(toks):\n",
    "        new_toks = [tok for tok in toks if tok not in stopwords.words('english')]\n",
    "        return new_toks\n",
    "    \n",
    "    df = data.copy()\n",
    "    df['no_stop_word'] = df[col].apply(operation)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae5f6dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "      <th>message_lam</th>\n",
       "      <th>no_stop_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[rt, research, say, we, have, three, year, to,...</td>\n",
       "      <td>[rt, researcher, say, we, have, three, year, t...</td>\n",
       "      <td>[rt, researcher, say, three, year, act, climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "      <td>[wire, 2016, was, a, pivot, year, in, the, war...</td>\n",
       "      <td>[wired, 2016, wa, a, pivotal, year, in, the, w...</td>\n",
       "      <td>[wired, 2016, wa, pivotal, year, war, climate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climat,...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climate...</td>\n",
       "      <td>[rt, 2016, racist, sexist, climate, change, de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2  rt  researchers say we have three years to act...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...   \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...   \n",
       "\n",
       "                                        message_stem  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evid, of, anthropoge...   \n",
       "2  [rt, research, say, we, have, three, year, to,...   \n",
       "3  [wire, 2016, was, a, pivot, year, in, the, war...   \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climat,...   \n",
       "\n",
       "                                         message_lam  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...   \n",
       "2  [rt, researcher, say, we, have, three, year, t...   \n",
       "3  [wired, 2016, wa, a, pivotal, year, in, the, w...   \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climate...   \n",
       "\n",
       "                                        no_stop_word  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [like, lack, evidence, anthropogenic, global, ...  \n",
       "2  [rt, researcher, say, three, year, act, climat...  \n",
       "3  [wired, 2016, wa, pivotal, year, war, climate,...  \n",
       "4  [rt, 2016, racist, sexist, climate, change, de...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column from message_lam void of stop words\n",
    "new_df_train = remove_stop_words(new_df_train, 'message_lam')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76186b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ef376fd",
   "metadata": {},
   "source": [
    "### Transforming text into numbers\n",
    "\n",
    "Most models do not work well with text, hence the need to convert our text into numbers. To execute this task and more, we use **CountVectorizer** a package from sklearn library.\n",
    "**CountVectorizer** has some **hyperparameters** which we can asign desired values to while initialising. \n",
    "The **hyperparameters** that we shall be tunning for these work are: \n",
    "\n",
    "- **max_df** :  When building the vocabulary ignore terms that have a document frequency strictly higher than the                     given threshold (corpus-specific stop words). If float, the parameter represents a proportion of                       documents,integer absolute counts.This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **min_df** :  When building the vocabulary ignore terms that have a document frequency strictly lower than the given                 threshold. This value is also called cut-off in the literature. If float, the parameter represents a                   proportion of documents, integer absolute counts.This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **max_features**: If not None, build a vocabulary that only consider the top max_features ordered by term frequency                     across the corpus. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **analyzer**: Whether the feature should be made of word n-gram or character n-grams. Option ‘char_wb’ creates                       character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with                 space.\n",
    "\n",
    "- **ngram_range**: The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to                    be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5d2c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_20 = CountVectorizer(max_features=20,analyzer='word', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78213bc",
   "metadata": {},
   "source": [
    "### Convert processed words to corpus\n",
    "\n",
    "Before we can transform the words in numeric type, for each column we have to remove the delimeters introduced during tokennization. This process is needed to enable us form a **corpus**.\n",
    "To achieve this, we write a function **form_corpus**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42c773f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_corpus(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column with tokenized text, \n",
    "        returns a new dataframe with an additional column(de_tok), which is made up of all words in the inserted colunm\n",
    "        but void of delimeters.\n",
    "    \"\"\"\n",
    "    def operation(tok_list):\n",
    "        string = ' '.join(tok_list)\n",
    "        return string\n",
    "    df = data.copy()\n",
    "    df['de_tok'] = df[col].apply(operation)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38167fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "      <th>message_lam</th>\n",
       "      <th>no_stop_word</th>\n",
       "      <th>de_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[rt, research, say, we, have, three, year, to,...</td>\n",
       "      <td>[rt, researcher, say, we, have, three, year, t...</td>\n",
       "      <td>[rt, researcher, say, three, year, act, climat...</td>\n",
       "      <td>rt researcher say three year act climate chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "      <td>[wire, 2016, was, a, pivot, year, in, the, war...</td>\n",
       "      <td>[wired, 2016, wa, a, pivotal, year, in, the, w...</td>\n",
       "      <td>[wired, 2016, wa, pivotal, year, war, climate,...</td>\n",
       "      <td>wired 2016 wa pivotal year war climate change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climat,...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climate...</td>\n",
       "      <td>[rt, 2016, racist, sexist, climate, change, de...</td>\n",
       "      <td>rt 2016 racist sexist climate change denying b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2  rt  researchers say we have three years to act...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...   \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...   \n",
       "\n",
       "                                        message_stem  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evid, of, anthropoge...   \n",
       "2  [rt, research, say, we, have, three, year, to,...   \n",
       "3  [wire, 2016, was, a, pivot, year, in, the, war...   \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climat,...   \n",
       "\n",
       "                                         message_lam  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...   \n",
       "2  [rt, researcher, say, we, have, three, year, t...   \n",
       "3  [wired, 2016, wa, a, pivotal, year, in, the, w...   \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climate...   \n",
       "\n",
       "                                        no_stop_word  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [like, lack, evidence, anthropogenic, global, ...   \n",
       "2  [rt, researcher, say, three, year, act, climat...   \n",
       "3  [wired, 2016, wa, pivotal, year, war, climate,...   \n",
       "4  [rt, 2016, racist, sexist, climate, change, de...   \n",
       "\n",
       "                                              de_tok  \n",
       "0  polyscimajor epa chief doesnt think carbon dio...  \n",
       "1    like lack evidence anthropogenic global warming  \n",
       "2  rt researcher say three year act climate chang...  \n",
       "3      wired 2016 wa pivotal year war climate change  \n",
       "4  rt 2016 racist sexist climate change denying b...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column from no_stop_word void of delimeters\n",
    "new_df_train = form_corpus(new_df_train, 'no_stop_word')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12b92c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>de_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt researcher say three year act climate chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired 2016 wa pivotal year war climate change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt 2016 racist sexist climate change denying b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             de_tok\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...\n",
       "1          1    like lack evidence anthropogenic global warming\n",
       "2          2  rt researcher say three year act climate chang...\n",
       "3          1      wired 2016 wa pivotal year war climate change\n",
       "4          1  rt 2016 racist sexist climate change denying b..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop every other columns except sentiment and de_tok columns\n",
    "df_train_reduced = new_df_train[['sentiment', 'de_tok']]\n",
    "df_train_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "584fc9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 20)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the de_tok column\n",
    "X_count = vect_20.fit_transform(df_train_reduced['de_tok'].values.astype(str))\n",
    "X_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec762ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    1\n",
       "8    1\n",
       "9    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the dependant variable into a variable\n",
    "y = df_train_reduced['sentiment']\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ade51fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amp',\n",
       " 'believe',\n",
       " 'believe climate',\n",
       " 'believe climate change',\n",
       " 'change',\n",
       " 'climate',\n",
       " 'climate change',\n",
       " 'doesnt',\n",
       " 'global',\n",
       " 'global warming',\n",
       " 'going',\n",
       " 'people',\n",
       " 'real',\n",
       " 'rt',\n",
       " 'say',\n",
       " 'shes',\n",
       " 'think',\n",
       " 'trump',\n",
       " 'warming',\n",
       " 'world']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See feature names\n",
    "vect_20.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f84351e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 1, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe66104c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amp</th>\n",
       "      <th>believe</th>\n",
       "      <th>believe climate</th>\n",
       "      <th>believe climate change</th>\n",
       "      <th>change</th>\n",
       "      <th>climate</th>\n",
       "      <th>climate change</th>\n",
       "      <th>doesnt</th>\n",
       "      <th>global</th>\n",
       "      <th>global warming</th>\n",
       "      <th>going</th>\n",
       "      <th>people</th>\n",
       "      <th>real</th>\n",
       "      <th>rt</th>\n",
       "      <th>say</th>\n",
       "      <th>shes</th>\n",
       "      <th>think</th>\n",
       "      <th>trump</th>\n",
       "      <th>warming</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amp  believe  believe climate  believe climate change  change  climate  \\\n",
       "0    0        0                0                       0       0        0   \n",
       "1    0        0                0                       0       0        0   \n",
       "2    0        0                0                       0       1        1   \n",
       "3    0        0                0                       0       1        1   \n",
       "4    0        0                0                       0       1        1   \n",
       "\n",
       "   climate change  doesnt  global  global warming  going  people  real  rt  \\\n",
       "0               0       1       1               1      0       0     0   0   \n",
       "1               0       0       1               1      0       0     0   0   \n",
       "2               1       0       0               0      0       0     0   1   \n",
       "3               1       0       0               0      0       0     0   0   \n",
       "4               1       0       0               0      0       0     0   1   \n",
       "\n",
       "   say  shes  think  trump  warming  world  \n",
       "0    0     0      1      0        1      0  \n",
       "1    0     0      0      0        1      0  \n",
       "2    1     0      0      0        0      0  \n",
       "3    0     0      0      0        0      0  \n",
       "4    0     0      0      0        0      0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = pd.DataFrame(data=X_count.toarray(),columns = vect_20.get_feature_names())\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to create one or more regression models that are able to accurately predict the thee hour load shortfall. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f8ca1",
   "metadata": {},
   "source": [
    "### Logistics Regression\n",
    "\n",
    "We proceed to create a **Logistics Regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one or more ML models\n",
    "logreg = LogisticRegression(multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076f3bb",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "\n",
    "We fit the model with the features(**model_df**) and the dependant (**y**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed192263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model generated above\n",
    "log_fit = logreg.fit(model_df, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "To enable us make prediction with our model, we have to import the **test** dataset and execute all data engineering operation executed on the **train** dataset.\n",
    "\n",
    "These activities are: \n",
    "- **delete urls**\n",
    "- **delete tags**\n",
    "- **convert words to lowercases**\n",
    "- **remove punctions**\n",
    "- **remove newlines**\n",
    "- **tokenize**\n",
    "- **stemming**\n",
    "- **larmming**\n",
    "- **remove stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9af6c562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and view the first 5 rolls of our training dataset\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bba2956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with message colun void of url links\n",
    "new_df_test = delete_url(df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ae0d984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nPutin got to you too Jill ! \\nTrump does...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT : 'Female orgasms cause global warming!'\\n-...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3      \\nPutin got to you too Jill ! \\nTrump does...   476263\n",
       "4  RT : 'Female orgasms cause global warming!'\\n-...   872928"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with message colun void of url links\n",
    "new_df_test = delete_tags(new_df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebf021a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe will now be looking to china to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nputin got to you too jill ! \\ntrump does...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt : 'female orgasms cause global warming!'\\n-...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  europe will now be looking to china to make su...   169760\n",
       "1  combine this with the polling of staffers re c...    35326\n",
       "2  the scary, unimpeachable evidence that climate...   224985\n",
       "3      \\nputin got to you too jill ! \\ntrump does...   476263\n",
       "4  rt : 'female orgasms cause global warming!'\\n-...   872928"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with all words in the message column converted to its lowercase form\n",
    "new_df_test = word_converter(new_df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f100a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe will now be looking to china to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the scary unimpeachable evidence that climate ...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nputin got to you too jill  \\ntrump doesn...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt  female orgasms cause global warming\\nsarca...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  europe will now be looking to china to make su...   169760\n",
       "1  combine this with the polling of staffers re c...    35326\n",
       "2  the scary unimpeachable evidence that climate ...   224985\n",
       "3      \\nputin got to you too jill  \\ntrump doesn...   476263\n",
       "4  rt  female orgasms cause global warming\\nsarca...   872928"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with the message colmn void of punctuations\n",
    "new_df_test = remove_punc(new_df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8e8b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I noticed we have the new line command (\\n) starting some words, we wrote a function to remove new line command\n",
    "\n",
    "def remove_new_line(data, col):\n",
    "    \"\"\"\n",
    "        Takes in a dataframe and a column, returns a new dataframe with a new column void of new line command\n",
    "    \"\"\"\n",
    "\n",
    "    def operation(text):\n",
    "        result = re.sub(\"\\n\", \"\", text)\n",
    "        return result\n",
    "\n",
    "    df = data.copy()\n",
    "    \n",
    "    df[col] = df[col].apply(operation)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adfb8f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe will now be looking to china to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the scary unimpeachable evidence that climate ...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got to you too jill  trump doesnt be...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt  female orgasms cause global warmingsarcast...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  europe will now be looking to china to make su...   169760\n",
       "1  combine this with the polling of staffers re c...    35326\n",
       "2  the scary unimpeachable evidence that climate ...   224985\n",
       "3      putin got to you too jill  trump doesnt be...   476263\n",
       "4  rt  female orgasms cause global warmingsarcast...   872928"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with the message colmn void of punctuations\n",
    "new_df_test = remove_new_line(new_df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2cc8a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe will now be looking to china to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>[europe, will, now, be, looking, to, china, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>[combine, this, with, the, polling, of, staffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the scary unimpeachable evidence that climate ...</td>\n",
       "      <td>224985</td>\n",
       "      <td>[the, scary, unimpeachable, evidence, that, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got to you too jill  trump doesnt be...</td>\n",
       "      <td>476263</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt  female orgasms cause global warmingsarcast...</td>\n",
       "      <td>872928</td>\n",
       "      <td>[rt, female, orgasms, cause, global, warmingsa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  \\\n",
       "0  europe will now be looking to china to make su...   169760   \n",
       "1  combine this with the polling of staffers re c...    35326   \n",
       "2  the scary unimpeachable evidence that climate ...   224985   \n",
       "3      putin got to you too jill  trump doesnt be...   476263   \n",
       "4  rt  female orgasms cause global warmingsarcast...   872928   \n",
       "\n",
       "                                         message_tok  \n",
       "0  [europe, will, now, be, looking, to, china, to...  \n",
       "1  [combine, this, with, the, polling, of, staffe...  \n",
       "2  [the, scary, unimpeachable, evidence, that, cl...  \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...  \n",
       "4  [rt, female, orgasms, cause, global, warmingsa...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold the tokens from message column\n",
    "new_df_test = tokenizer(new_df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0bf2fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe will now be looking to china to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>[europe, will, now, be, looking, to, china, to...</td>\n",
       "      <td>[europ, will, now, be, look, to, china, to, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>[combine, this, with, the, polling, of, staffe...</td>\n",
       "      <td>[combin, this, with, the, poll, of, staffer, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the scary unimpeachable evidence that climate ...</td>\n",
       "      <td>224985</td>\n",
       "      <td>[the, scary, unimpeachable, evidence, that, cl...</td>\n",
       "      <td>[the, scari, unimpeach, evid, that, climat, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got to you too jill  trump doesnt be...</td>\n",
       "      <td>476263</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt  female orgasms cause global warmingsarcast...</td>\n",
       "      <td>872928</td>\n",
       "      <td>[rt, female, orgasms, cause, global, warmingsa...</td>\n",
       "      <td>[rt, femal, orgasm, caus, global, warmingsarca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  \\\n",
       "0  europe will now be looking to china to make su...   169760   \n",
       "1  combine this with the polling of staffers re c...    35326   \n",
       "2  the scary unimpeachable evidence that climate ...   224985   \n",
       "3      putin got to you too jill  trump doesnt be...   476263   \n",
       "4  rt  female orgasms cause global warmingsarcast...   872928   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [europe, will, now, be, looking, to, china, to...   \n",
       "1  [combine, this, with, the, polling, of, staffe...   \n",
       "2  [the, scary, unimpeachable, evidence, that, cl...   \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...   \n",
       "4  [rt, female, orgasms, cause, global, warmingsa...   \n",
       "\n",
       "                                        message_stem  \n",
       "0  [europ, will, now, be, look, to, china, to, ma...  \n",
       "1  [combin, this, with, the, poll, of, staffer, r...  \n",
       "2  [the, scari, unimpeach, evid, that, climat, ch...  \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...  \n",
       "4  [rt, femal, orgasm, caus, global, warmingsarca...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold root words from stemmer\n",
    "new_df_test = stem_words(new_df_test, 'message_tok')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fafa2ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "      <th>message_lam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe will now be looking to china to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>[europe, will, now, be, looking, to, china, to...</td>\n",
       "      <td>[europ, will, now, be, look, to, china, to, ma...</td>\n",
       "      <td>[europe, will, now, be, looking, to, china, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>[combine, this, with, the, polling, of, staffe...</td>\n",
       "      <td>[combin, this, with, the, poll, of, staffer, r...</td>\n",
       "      <td>[combine, this, with, the, polling, of, staffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the scary unimpeachable evidence that climate ...</td>\n",
       "      <td>224985</td>\n",
       "      <td>[the, scary, unimpeachable, evidence, that, cl...</td>\n",
       "      <td>[the, scari, unimpeach, evid, that, climat, ch...</td>\n",
       "      <td>[the, scary, unimpeachable, evidence, that, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got to you too jill  trump doesnt be...</td>\n",
       "      <td>476263</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt  female orgasms cause global warmingsarcast...</td>\n",
       "      <td>872928</td>\n",
       "      <td>[rt, female, orgasms, cause, global, warmingsa...</td>\n",
       "      <td>[rt, femal, orgasm, caus, global, warmingsarca...</td>\n",
       "      <td>[rt, female, orgasm, cause, global, warmingsar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  \\\n",
       "0  europe will now be looking to china to make su...   169760   \n",
       "1  combine this with the polling of staffers re c...    35326   \n",
       "2  the scary unimpeachable evidence that climate ...   224985   \n",
       "3      putin got to you too jill  trump doesnt be...   476263   \n",
       "4  rt  female orgasms cause global warmingsarcast...   872928   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [europe, will, now, be, looking, to, china, to...   \n",
       "1  [combine, this, with, the, polling, of, staffe...   \n",
       "2  [the, scary, unimpeachable, evidence, that, cl...   \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...   \n",
       "4  [rt, female, orgasms, cause, global, warmingsa...   \n",
       "\n",
       "                                        message_stem  \\\n",
       "0  [europ, will, now, be, look, to, china, to, ma...   \n",
       "1  [combin, this, with, the, poll, of, staffer, r...   \n",
       "2  [the, scari, unimpeach, evid, that, climat, ch...   \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...   \n",
       "4  [rt, femal, orgasm, caus, global, warmingsarca...   \n",
       "\n",
       "                                         message_lam  \n",
       "0  [europe, will, now, be, looking, to, china, to...  \n",
       "1  [combine, this, with, the, polling, of, staffe...  \n",
       "2  [the, scary, unimpeachable, evidence, that, cl...  \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...  \n",
       "4  [rt, female, orgasm, cause, global, warmingsar...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold root words from stemmer\n",
    "new_df_test = lam_words(new_df_test, 'message_tok')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f489630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "      <th>message_lam</th>\n",
       "      <th>no_stop_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe will now be looking to china to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>[europe, will, now, be, looking, to, china, to...</td>\n",
       "      <td>[europ, will, now, be, look, to, china, to, ma...</td>\n",
       "      <td>[europe, will, now, be, looking, to, china, to...</td>\n",
       "      <td>[europe, looking, china, make, sure, alone, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>[combine, this, with, the, polling, of, staffe...</td>\n",
       "      <td>[combin, this, with, the, poll, of, staffer, r...</td>\n",
       "      <td>[combine, this, with, the, polling, of, staffe...</td>\n",
       "      <td>[combine, polling, staffer, climate, change, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the scary unimpeachable evidence that climate ...</td>\n",
       "      <td>224985</td>\n",
       "      <td>[the, scary, unimpeachable, evidence, that, cl...</td>\n",
       "      <td>[the, scari, unimpeach, evid, that, climat, ch...</td>\n",
       "      <td>[the, scary, unimpeachable, evidence, that, cl...</td>\n",
       "      <td>[scary, unimpeachable, evidence, climate, chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got to you too jill  trump doesnt be...</td>\n",
       "      <td>476263</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "      <td>[putin, got, jill, trump, doesnt, believe, cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt  female orgasms cause global warmingsarcast...</td>\n",
       "      <td>872928</td>\n",
       "      <td>[rt, female, orgasms, cause, global, warmingsa...</td>\n",
       "      <td>[rt, femal, orgasm, caus, global, warmingsarca...</td>\n",
       "      <td>[rt, female, orgasm, cause, global, warmingsar...</td>\n",
       "      <td>[rt, female, orgasm, cause, global, warmingsar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  \\\n",
       "0  europe will now be looking to china to make su...   169760   \n",
       "1  combine this with the polling of staffers re c...    35326   \n",
       "2  the scary unimpeachable evidence that climate ...   224985   \n",
       "3      putin got to you too jill  trump doesnt be...   476263   \n",
       "4  rt  female orgasms cause global warmingsarcast...   872928   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [europe, will, now, be, looking, to, china, to...   \n",
       "1  [combine, this, with, the, polling, of, staffe...   \n",
       "2  [the, scary, unimpeachable, evidence, that, cl...   \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...   \n",
       "4  [rt, female, orgasms, cause, global, warmingsa...   \n",
       "\n",
       "                                        message_stem  \\\n",
       "0  [europ, will, now, be, look, to, china, to, ma...   \n",
       "1  [combin, this, with, the, poll, of, staffer, r...   \n",
       "2  [the, scari, unimpeach, evid, that, climat, ch...   \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...   \n",
       "4  [rt, femal, orgasm, caus, global, warmingsarca...   \n",
       "\n",
       "                                         message_lam  \\\n",
       "0  [europe, will, now, be, looking, to, china, to...   \n",
       "1  [combine, this, with, the, polling, of, staffe...   \n",
       "2  [the, scary, unimpeachable, evidence, that, cl...   \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...   \n",
       "4  [rt, female, orgasm, cause, global, warmingsar...   \n",
       "\n",
       "                                        no_stop_word  \n",
       "0  [europe, looking, china, make, sure, alone, fi...  \n",
       "1  [combine, polling, staffer, climate, change, w...  \n",
       "2  [scary, unimpeachable, evidence, climate, chan...  \n",
       "3  [putin, got, jill, trump, doesnt, believe, cli...  \n",
       "4  [rt, female, orgasm, cause, global, warmingsar...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column from message_lam void of stop words\n",
    "new_df_test = remove_stop_words(new_df_test, 'message_lam')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da6c24dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "      <th>message_lam</th>\n",
       "      <th>no_stop_word</th>\n",
       "      <th>de_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe will now be looking to china to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>[europe, will, now, be, looking, to, china, to...</td>\n",
       "      <td>[europ, will, now, be, look, to, china, to, ma...</td>\n",
       "      <td>[europe, will, now, be, looking, to, china, to...</td>\n",
       "      <td>[europe, looking, china, make, sure, alone, fi...</td>\n",
       "      <td>europe looking china make sure alone fighting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>[combine, this, with, the, polling, of, staffe...</td>\n",
       "      <td>[combin, this, with, the, poll, of, staffer, r...</td>\n",
       "      <td>[combine, this, with, the, polling, of, staffe...</td>\n",
       "      <td>[combine, polling, staffer, climate, change, w...</td>\n",
       "      <td>combine polling staffer climate change woman r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the scary unimpeachable evidence that climate ...</td>\n",
       "      <td>224985</td>\n",
       "      <td>[the, scary, unimpeachable, evidence, that, cl...</td>\n",
       "      <td>[the, scari, unimpeach, evid, that, climat, ch...</td>\n",
       "      <td>[the, scary, unimpeachable, evidence, that, cl...</td>\n",
       "      <td>[scary, unimpeachable, evidence, climate, chan...</td>\n",
       "      <td>scary unimpeachable evidence climate change al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got to you too jill  trump doesnt be...</td>\n",
       "      <td>476263</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "      <td>[putin, got, to, you, too, jill, trump, doesnt...</td>\n",
       "      <td>[putin, got, jill, trump, doesnt, believe, cli...</td>\n",
       "      <td>putin got jill trump doesnt believe climate ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt  female orgasms cause global warmingsarcast...</td>\n",
       "      <td>872928</td>\n",
       "      <td>[rt, female, orgasms, cause, global, warmingsa...</td>\n",
       "      <td>[rt, femal, orgasm, caus, global, warmingsarca...</td>\n",
       "      <td>[rt, female, orgasm, cause, global, warmingsar...</td>\n",
       "      <td>[rt, female, orgasm, cause, global, warmingsar...</td>\n",
       "      <td>rt female orgasm cause global warmingsarcastic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  \\\n",
       "0  europe will now be looking to china to make su...   169760   \n",
       "1  combine this with the polling of staffers re c...    35326   \n",
       "2  the scary unimpeachable evidence that climate ...   224985   \n",
       "3      putin got to you too jill  trump doesnt be...   476263   \n",
       "4  rt  female orgasms cause global warmingsarcast...   872928   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [europe, will, now, be, looking, to, china, to...   \n",
       "1  [combine, this, with, the, polling, of, staffe...   \n",
       "2  [the, scary, unimpeachable, evidence, that, cl...   \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...   \n",
       "4  [rt, female, orgasms, cause, global, warmingsa...   \n",
       "\n",
       "                                        message_stem  \\\n",
       "0  [europ, will, now, be, look, to, china, to, ma...   \n",
       "1  [combin, this, with, the, poll, of, staffer, r...   \n",
       "2  [the, scari, unimpeach, evid, that, climat, ch...   \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...   \n",
       "4  [rt, femal, orgasm, caus, global, warmingsarca...   \n",
       "\n",
       "                                         message_lam  \\\n",
       "0  [europe, will, now, be, looking, to, china, to...   \n",
       "1  [combine, this, with, the, polling, of, staffe...   \n",
       "2  [the, scary, unimpeachable, evidence, that, cl...   \n",
       "3  [putin, got, to, you, too, jill, trump, doesnt...   \n",
       "4  [rt, female, orgasm, cause, global, warmingsar...   \n",
       "\n",
       "                                        no_stop_word  \\\n",
       "0  [europe, looking, china, make, sure, alone, fi...   \n",
       "1  [combine, polling, staffer, climate, change, w...   \n",
       "2  [scary, unimpeachable, evidence, climate, chan...   \n",
       "3  [putin, got, jill, trump, doesnt, believe, cli...   \n",
       "4  [rt, female, orgasm, cause, global, warmingsar...   \n",
       "\n",
       "                                              de_tok  \n",
       "0  europe looking china make sure alone fighting ...  \n",
       "1  combine polling staffer climate change woman r...  \n",
       "2  scary unimpeachable evidence climate change al...  \n",
       "3  putin got jill trump doesnt believe climate ch...  \n",
       "4  rt female orgasm cause global warmingsarcastic...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column from no_stop_word void of delimeters\n",
    "new_df_test = form_corpus(new_df_test, 'no_stop_word')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "775ba967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe looking china make sure alone fighting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine polling staffer climate change woman r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scary unimpeachable evidence climate change al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin got jill trump doesnt believe climate ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt female orgasm cause global warmingsarcastic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              de_tok\n",
       "0  europe looking china make sure alone fighting ...\n",
       "1  combine polling staffer climate change woman r...\n",
       "2  scary unimpeachable evidence climate change al...\n",
       "3  putin got jill trump doesnt believe climate ch...\n",
       "4  rt female orgasm cause global warmingsarcastic..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop every other columns except sentiment and de_tok columns\n",
    "df_test_reduced = new_df_test[[ 'de_tok']]\n",
    "df_test_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3cda4756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10546, 20)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the de_tok column\n",
    "X_count_test = vect_20.transform(df_test_reduced['de_tok'].values.astype(str))\n",
    "X_count_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "348aaee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amp</th>\n",
       "      <th>believe</th>\n",
       "      <th>believe climate</th>\n",
       "      <th>believe climate change</th>\n",
       "      <th>change</th>\n",
       "      <th>climate</th>\n",
       "      <th>climate change</th>\n",
       "      <th>doesnt</th>\n",
       "      <th>global</th>\n",
       "      <th>global warming</th>\n",
       "      <th>going</th>\n",
       "      <th>people</th>\n",
       "      <th>real</th>\n",
       "      <th>rt</th>\n",
       "      <th>say</th>\n",
       "      <th>shes</th>\n",
       "      <th>think</th>\n",
       "      <th>trump</th>\n",
       "      <th>warming</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amp  believe  believe climate  believe climate change  change  climate  \\\n",
       "0    0        0                0                       0       1        1   \n",
       "1    0        0                0                       0       1        1   \n",
       "2    0        0                0                       0       1        1   \n",
       "3    0        1                1                       1       1        1   \n",
       "4    0        0                0                       0       0        0   \n",
       "\n",
       "   climate change  doesnt  global  global warming  going  people  real  rt  \\\n",
       "0               1       0       0               0      0       0     0   0   \n",
       "1               1       0       0               0      0       0     0   0   \n",
       "2               1       0       0               0      0       0     0   0   \n",
       "3               1       1       0               0      0       0     0   0   \n",
       "4               0       0       1               0      0       0     0   1   \n",
       "\n",
       "   say  shes  think  trump  warming  world  \n",
       "0    0     0      0      0        0      0  \n",
       "1    0     0      0      0        0      0  \n",
       "2    0     0      0      0        0      0  \n",
       "3    0     0      1      1        0      0  \n",
       "4    0     0      0      0        0      0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.DataFrame(data=X_count_test.toarray(),columns = vect_20.get_feature_names())\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "y_pred_test = logreg.predict(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aa7580ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>895714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>875167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>78329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>867455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>470892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweetid  sentiment\n",
       "10541   895714          1\n",
       "10542   875167          1\n",
       "10543    78329          1\n",
       "10544   867455          1\n",
       "10545   470892          1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and view the first 5 rolls of our training dataset\n",
    "df_sample = pd.read_csv('data/sample_submission.csv')\n",
    "y_exact = df_sample['sentiment']\n",
    "df_sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1242af5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>RT @BrittanyBohrer: Brb, writing a poem about ...</td>\n",
       "      <td>895714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>2016: the year climate change came home: Durin...</td>\n",
       "      <td>875167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>RT @loop_vanuatu: Pacific countries positive a...</td>\n",
       "      <td>78329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>RT @xanria_00018: You’re so hot, you must be t...</td>\n",
       "      <td>867455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>RT @chloebalaoing: climate change is a global ...</td>\n",
       "      <td>470892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  tweetid\n",
       "10541  RT @BrittanyBohrer: Brb, writing a poem about ...   895714\n",
       "10542  2016: the year climate change came home: Durin...   875167\n",
       "10543  RT @loop_vanuatu: Pacific countries positive a...    78329\n",
       "10544  RT @xanria_00018: You’re so hot, you must be t...   867455\n",
       "10545  RT @chloebalaoing: climate change is a global ...   470892"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23fe9a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.80      0.89     10546\n",
      "           2       0.00      0.00      0.00         0\n",
      "           0       0.00      0.00      0.00         0\n",
      "          -1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.80     10546\n",
      "   macro avg       0.25      0.20      0.22     10546\n",
      "weighted avg       1.00      0.80      0.89     10546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_exact, y_pred_test, labels= [1,2,0,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4844e27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8893101632438125"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_exact, y_pred_test, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>872928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweetid  sentiment\n",
       "0   169760          1\n",
       "1    35326          1\n",
       "2   224985          1\n",
       "3   476263          1\n",
       "4   872928          1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose best model and motivate why it is the best choice\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'tweetid': df_sample['tweetid'],\n",
    "    'sentiment': y_pred_test\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "147a2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file_001.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83dd714",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ff741c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss chosen methods logic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
