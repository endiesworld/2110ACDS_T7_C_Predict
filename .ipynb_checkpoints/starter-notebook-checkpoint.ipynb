{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Clasification Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**2110ACDS_T7**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### EDSA-Climate Change Belief Analysis 2022\n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Our clients would like to know people's perception on climate change, whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received, which will increasing their insights and informing future marketing strategies.\n",
    "\n",
    "SWAT_Team_7 has been consulted to create a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "### Process\n",
    "\n",
    "- 1. analyse the supplied data;\n",
    "- 2. identify potential errors in the data and clean the existing data set;\n",
    "- 3. determine if additional features can be added to enrich the data set;\n",
    "- 4. build a model that is capable of forecasting the three hourly demand shortfalls;\n",
    "- 5. evaluate the accuracy of the best machine learning model;\n",
    "- 6. determine if a person believes in climate change or not, and\n",
    "- 7. explain the inner working of the model to a non-technical audience.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c044ea",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "For this section, we carry out two different types of data analysis:\n",
    "- Univariate \\\n",
    "    i. non-graphical \\\n",
    "    ii. graphical \n",
    "- Multivariate \\\n",
    "    i. non-graphical \\\n",
    "    ii. graphical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e773ee3",
   "metadata": {},
   "source": [
    "#### Univariate Non-Graphical Analysis\n",
    "For this analysis, we are going to view dataset on the below checks:  \\\n",
    "    i.  Check for the presence of *null* values  \\\n",
    "    ii. Descriptive statistical values *mean, std, minimum, quatiles, maximum, and kurtosis*  \n",
    "    iii. Dataset data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at data statistics\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254e20c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  15819 non-null  int64 \n",
      " 1   message    15819 non-null  object\n",
      " 2   tweetid    15819 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 370.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data types for all columns\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f855bfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>15819.0</td>\n",
       "      <td>0.917504</td>\n",
       "      <td>0.836537</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <td>15819.0</td>\n",
       "      <td>501719.433656</td>\n",
       "      <td>289045.983132</td>\n",
       "      <td>6.0</td>\n",
       "      <td>253207.5</td>\n",
       "      <td>502291.0</td>\n",
       "      <td>753769.0</td>\n",
       "      <td>999888.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count           mean            std  min       25%       50%  \\\n",
       "sentiment  15819.0       0.917504       0.836537 -1.0       1.0       1.0   \n",
       "tweetid    15819.0  501719.433656  289045.983132  6.0  253207.5  502291.0   \n",
       "\n",
       "                75%       max  \n",
       "sentiment       1.0       2.0  \n",
       "tweetid    753769.0  999888.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at data statistics\n",
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05422a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0.122976\n",
       "tweetid     -1.193356\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf02c5b",
   "metadata": {},
   "source": [
    "From the above analysis thus far, it is evidence that we only have two numeric colunms. \n",
    "However we suspect that one of these columns(tweetid) contains unique values in each row, while the other column(sentiment) from the name, we infere that it is our label, hence contains a minimum of two different values.\n",
    "\n",
    "To confirm the above, we write a function that takes in a dataframe and a column-id, to give an output which is the number of unique values in the column as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e95c1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_val(df, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column name, \n",
    "        and ouputs an interger, which is the number of unique \n",
    "        values in the column.\n",
    "    \"\"\"\n",
    "    return df[col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a22e6980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers of unique values in the sentiment column is : 4\n"
     ]
    }
   ],
   "source": [
    "# Check the numbers of unique values for the sentiment column\n",
    "print(f'The numbers of unique values in the sentiment column is : {unique_val(df_train, \"sentiment\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e48c18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers of unique values in the tweetid column is : 15819\n"
     ]
    }
   ],
   "source": [
    "# Check the numbers of unique values for the tweetid column\n",
    "print(f'The numbers of unique values in the tweetid column is : {unique_val(df_train, \"tweetid\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e2880",
   "metadata": {},
   "source": [
    "From the above results, the sentiment column contains four different unique values, and we want to see how this values\n",
    "are distributed in the column.\n",
    "To achieve this, we write a function called *unique_val_count*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80cd6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_val_count(df, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column name, \n",
    "        and ouputs a dictionary, which contains the unique values as a key, and the numbers as values.\n",
    "    \"\"\"\n",
    "    distribution = {}\n",
    "    unique_vals = df[col].unique()\n",
    "    for val in unique_vals:\n",
    "        distribution[val] = df[df[col] == val][col].count()\n",
    "    \n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29ddf06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 8530, 2: 3640, 0: 2353, -1: 1296}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_val_count(df_train, 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd562db5",
   "metadata": {},
   "source": [
    "### Univariate graphical inspection of data\n",
    "For this analysis, we view the individual colunms using histogram plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3f47bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot of label classes\n",
    "fig,ax = plt.subplots()\n",
    "df_train['sentiment'].value_counts().plot(kind = 'bar', facecolor='g', alpha=0.65)\n",
    "ax.set_xlabel('Sentiments')\n",
    "ax.set_ylabel('Sentiments count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74b341",
   "metadata": {},
   "source": [
    "# PUT IN WORD CLOUD BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1525812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77b34f68",
   "metadata": {},
   "source": [
    "## Also include findings from world cloud in EDA summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f2a7d",
   "metadata": {},
   "source": [
    "### EDA summary\n",
    "- The dataset contains three columns (sentiments, message and tweetid)\n",
    "- Sentiments and tweetid are of numeric data type, while message is non-numeric\n",
    "- tweetid is a clumn with uniques values acreoss the entire rows of the dataset\n",
    "- sentiments columns contains for different unique values (-1, 0, 1 &2) with different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at feature distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to: clean the dataset, and possibly create new features - as identified in the EDA phase. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ced808",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    "\n",
    "### Removing Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba0d8c",
   "metadata": {},
   "source": [
    "For the given dataset, we identified that the *message* column contains the novel tweet for each userid, which we are espected to classify. \n",
    "For us to proceed we have to carry out cleaning on this messages. This cleaning will be achieved through:\n",
    "* identify and remove web-urls from the main message \n",
    "* idendify and remove words started with '#'\n",
    "* idendify and remove words started with '@'\n",
    "* making everything lower case\n",
    "* removing punctuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab1ea8",
   "metadata": {},
   "source": [
    "#### Remove web-url from message\n",
    "\n",
    "We write a function called *delete_url*. This function uses regex to identify web-url in a column and remove same from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_url(data, col):\n",
    "    \"\"\"\n",
    "        Accepts a dataframe and col., removes web urls from the col.\n",
    "        returns a new dataframe \n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "    subs_url = ''\n",
    "    df[col] = df[col].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "98fa8207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with message colun void of url links\n",
    "new_df_train = delete_url(df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "84eea17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!?  via @mashable\""
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the above operation was successful \n",
    "new_df_train['message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "59692724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['message'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b3c36",
   "metadata": {},
   "source": [
    "### Remove '#' and '@' words\n",
    "\n",
    "We write a function *delete_tags*, to identify and remove words started with '#' and '@'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "92a0f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tags(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a col, removes all words started with '#' and '@' in the column,\n",
    "        and returns a new dataframe\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    pattern_tags = r'#\\w+[#?]'\n",
    "    pattern_2 = r'@\\w+'\n",
    "    subs_tag = ''\n",
    "    df[col] = df[col].replace(to_replace = pattern_tags, value = subs_tag, regex = True)\n",
    "    df[col] = df[col].replace(to_replace = pattern_2, value = subs_tag, regex = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8422fbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT : Researchers say we have three years to ac...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>WIRED : 2016 was a pivotal year in the war on...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT : It's 2016, and a racist, sexist, climate ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT : Researchers say we have three years to ac...   698562\n",
       "3          1   WIRED : 2016 was a pivotal year in the war on...   573736\n",
       "4          1  RT : It's 2016, and a racist, sexist, climate ...   466954"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with message colun void of url links\n",
    "new_df_train = delete_tags(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ec814",
   "metadata": {},
   "source": [
    "### Convert capitalized words to lowercase words\n",
    "\n",
    "We write a function *word_converter* to convert capitalized words to lowercase words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bcb93891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_converter(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and col, converts all capitalized words in the column to lowercase,\n",
    "        and returns a new dataframe.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    df[col] = df[col].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5ac78c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt : researchers say we have three years to ac...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired : 2016 was a pivotal year in the war on...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt : it's 2016, and a racist, sexist, climate ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief doesn't think carbon di...   625221\n",
       "1          1  it's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  rt : researchers say we have three years to ac...   698562\n",
       "3          1   wired : 2016 was a pivotal year in the war on...   573736\n",
       "4          1  rt : it's 2016, and a racist, sexist, climate ...   466954"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with all words in the message column converted to its lowercase form\n",
    "new_df_train = word_converter(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f51a4",
   "metadata": {},
   "source": [
    "### Remove punctuation\n",
    "\n",
    "We write a function *remove_punc* that uses the string package from python to remove punctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "87a4a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column, uses python string package to identify and remove all\n",
    "        punctions in the column. It returns a new dataframe\n",
    "    \"\"\"\n",
    "    def operation(post):\n",
    "        return ''.join([l for l in post if l not in string.punctuation])\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    df[col] = df[col].apply(operation)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e7548016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221\n",
       "1          1  its not like we lack evidence of anthropogenic...   126103\n",
       "2          2  rt  researchers say we have three years to act...   698562\n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736\n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with the message colmn void of punctuations\n",
    "new_df_train = remove_punc(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa36e01",
   "metadata": {},
   "source": [
    "### Tokenisation\n",
    "\n",
    "We write a function *tokenizer* to tokenize the words in the message column and store same in a new column named *message_tok*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "897e0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a col, creates a new column to store the tokenized words\n",
    "        in the inputed column, and returns a new dataframe.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    tokeniser = TreebankWordTokenizer()\n",
    "    df['message_tok'] = df[col].apply(tokeniser.tokenize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ea5182f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2  rt  researchers say we have three years to act...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954   \n",
       "\n",
       "                                         message_tok  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...  \n",
       "2  [rt, researchers, say, we, have, three, years,...  \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...  \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold the tokens from message column\n",
    "new_df_train = tokenizer(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c845c",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "We write a function *stem_words* to transform all words in the *message_tok* column to its root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4957f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(data, col):\n",
    "    \"\"\"\n",
    "        Takes in a dataframe and a column, converts the words in the column to it root form,\n",
    "        with the aid of SnowballStemmer class from the nltk package.\n",
    "        Returns a new dataframe with an additional column \"message_stem\"\n",
    "    \"\"\"\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    def operation(words, stemmer):\n",
    "        return [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    df = data.copy()\n",
    "    df[\"message_stem\"] = df[col].apply(operation, args=(stemmer, ))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "09d2c7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[rt, research, say, we, have, three, year, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "      <td>[wire, 2016, was, a, pivot, year, in, the, war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climat,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2  rt  researchers say we have three years to act...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...   \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...   \n",
       "\n",
       "                                        message_stem  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [it, not, like, we, lack, evid, of, anthropoge...  \n",
       "2  [rt, research, say, we, have, three, year, to,...  \n",
       "3  [wire, 2016, was, a, pivot, year, in, the, war...  \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climat,...  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold root words from stemmer\n",
    "new_df_train = stem_words(new_df_train, 'message_tok')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c55afc",
   "metadata": {},
   "source": [
    "### Larmming\n",
    "\n",
    "We write a function *lam_words* to transform all words in the *message_tok* column to its root form using Lemmatization, to enable us acrter for the shortfall in stemming above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "148e0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lam_words(data, col):\n",
    "    \"\"\"\n",
    "        Takes in a dataframe and a column, converts the words in the column to it root form,\n",
    "        with the aid of WordNetLemmatizer class from the nltk package.\n",
    "        Returns a new dataframe with an additional column \"message_lam\"\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def operation(words, lemmatizer):\n",
    "        return [lemmatizer.lemmatize(word) for word in words] \n",
    "    df = data.copy()\n",
    "    df[\"message_lam\"] = df[col].apply(operation, args=(lemmatizer, ))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ea6ae293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "      <th>message_lam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[rt, research, say, we, have, three, year, to,...</td>\n",
       "      <td>[rt, researcher, say, we, have, three, year, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "      <td>[wire, 2016, was, a, pivot, year, in, the, war...</td>\n",
       "      <td>[wired, 2016, wa, a, pivotal, year, in, the, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climat,...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2  rt  researchers say we have three years to act...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...   \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...   \n",
       "\n",
       "                                        message_stem  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evid, of, anthropoge...   \n",
       "2  [rt, research, say, we, have, three, year, to,...   \n",
       "3  [wire, 2016, was, a, pivot, year, in, the, war...   \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climat,...   \n",
       "\n",
       "                                         message_lam  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...  \n",
       "2  [rt, researcher, say, we, have, three, year, t...  \n",
       "3  [wired, 2016, wa, a, pivotal, year, in, the, w...  \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climate...  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold root words from stemmer\n",
    "new_df_train = lam_words(new_df_train, 'message_tok')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4510e4f",
   "metadata": {},
   "source": [
    "### Remove stop words here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebade9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f7b3d2c",
   "metadata": {},
   "source": [
    "### Do bag of words here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to create one or more regression models that are able to accurately predict the thee hour load shortfall. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets and features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one or more ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model and motivate why it is the best choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff741c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss chosen methods logic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
